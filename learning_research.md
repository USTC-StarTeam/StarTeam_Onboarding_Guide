<div align="center">
  <img src="https://avatars.githubusercontent.com/u/128775730?s=200&v=4" alt="Lab Logo" width="120" height="120">
  
  <h1 align="center">🧪 StarTeam Onboarding Guide | 实验室新生入门指南</h1>
  
  <p align="center">
    <strong>From Undergraduate to Researcher: The Definitive Roadmap</strong>
  </p>

  <p>
    <a href="https://e1nqigcg04q.feishu.cn/wiki/FvnNwEmSriz9v9kpKGscoyFdnhg">
      <img src="https://img.shields.io/badge/Server-Resource_Wiki-blue?style=flat-square&logo=confluence" alt="Server Wiki">
    </a>
    <a href="https://e1nqigcg04q.feishu.cn/wiki/DzVvwcdKnilb3pkSZmvciYl3nNc">
      <img src="https://img.shields.io/badge/Tools-Zotero_Guide-green?style=flat-square&logo=zotero" alt="Zotero Guide">
    </a>
    <img src="https://img.shields.io/badge/Focus-Recommender_Systems-orange?style=flat-square" alt="Focus Areas">
    <img src="https://img.shields.io/badge/Methodology-Data--Centric-red?style=flat-square" alt="Data-Centric AI">
  </p>
</div>

---

## 📖 Table of Contents (目录)

- [🔬 About The Lab](#-about-the-lab)
- [📅 Phase 0: 开发环境与工具](#-phase-0-开发环境与工具准备)
- [📚 Phase 1: 数学与深度学习基础](#-phase-1-数学与深度学习基础)
- [🚀 Phase 2: 实验室研究方向入门路线](#-phase-2-实验室研究方向入门路线)
    - [🏠 Direction A: Recommender Systems](#-direction-a-recommender-systems-推荐系统)
    - [🤖 Direction B: Large Language Models](#-direction-b-large-language-models-大模型)
    - [🧬 Direction C: AI4Science](#-direction-c-ai4science-科学智能)
- [🤝 Contributing](#-contributing)

---

## 🔬 About The Lab

欢迎加入 **StarTeam**！🎉 

本实验室专注于 **Recommender Systems (推荐系统)**、 **Large Language Model (大模型)**、 **AI4Science** 领域的前沿研究。

并特别致力于 **Data-Centric AI**（以数据为中心的 AI）方法论在大模型和推荐系统中的落地与应用。

这份文档旨在帮助你快速完成从“本科生”到“研究生”的角色转换。

---

## 📅 Phase 0: 开发环境与工具准备

> **Goal:** 工欲善其事，必先利其器。请熟悉实验室计算资源，并搭建高效的科研开发环境。

### 1. 实验室计算资源
服务器是进行模型训练的核心平台，请务必仔细阅读使用规范。

* **使用指南**: 👉 **[实验室服务器资源 Wiki](https://e1nqigcg04q.feishu.cn/wiki/FvnNwEmSriz9v9kpKGscoyFdnhg)**
* **账号申请**: 按照 Wiki 流程申请账号及配置 SSH 密钥。

### 2. 开发环境与 AI 工具链
推荐采用集成 AI 辅助功能的现代化工具，以提升编码效率。

* **基础技能**:
    * **Python & Conda**: 掌握使用 Anaconda/Miniconda 管理独立的虚拟环境。
    * **Linux**: 熟悉基本命令与远程开发 (推荐教程：[The Missing Semester](https://missing.csail.mit.edu/))。
    * **Git**: 掌握基本的代码版本控制 (Commit, Push, Pull, Branch)。
* **IDE (编辑器)**:
    * **Cursor**: 集成 AI 的代码编辑器，支持 Composer 模式进行多文件辅助编程。
    * **VS Code**: 如使用 VS Code，可安装 GitHub Copilot 或 Gemini Code Assist 等插件。

### 3. 学术科研工具
* **文献管理**: 推荐 **Zotero**，**配置指南**参考 👉 **[实验室 Zotero 使用手册](https://e1nqigcg04q.feishu.cn/wiki/DzVvwcdKnilb3pkSZmvciYl3nNc)**。
* **论文写作**: 注册 **[Overleaf](https://www.overleaf.com/)** 账号，建议尽早适应 LaTeX 排版。
* **资源搜索**: **[Google Scholar](https://scholar.google.com/)**: 学术搜索首选 | **[arXiv](https://arxiv.org/)** / **[AlphaXiv](https://www.alphaxiv.org/)**: 最新预印本论文及在线讨论 | **[Connected Papers](https://www.connectedpapers.com/)**: 可视化论文引用关系网。

---

## 📚 Phase 1: 数学与深度学习基础

> **Goal:** 建立以概率视角为核心的数学直觉，并掌握深度学习的理论框架。

### 1. 数学基础 (Theoretical Foundations)
* **《Probabilistic Machine Learning》 (MLAPP)** - Kevin Murphy
    * [Official Book Page](https://probml.github.io/pml-book/) | 现代机器学习的概率框架。
* **参考资料**: 《机器学习》(周志华), 《统计学习方法》(李航)。

### 2. 深度学习 (Deep Learning Core)
* **Deep Learning Course** - 李宏毅
    * [课程主页](https://speech.ee.ntu.edu.tw/~hylee/ml/2024-spring.php) | 涵盖 Transformer, RLHF 等前沿技术。
* **Dive into Deep Learning** - 李沐
    * [B站视频](https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497) | 理论与 PyTorch 代码结合。

### 3. 科研技巧 (Research Skills)
* **沈向洋: You are how you read**: [视频](https://www.bilibili.com/video/BV1df4y1m74k)
* **李沐: 论文精读系列**: [视频列表](https://space.bilibili.com/1567748478/channel/seriesdetail?sid=418476)
* **如何做好 Presentation**: [知乎博客](https://www.zhihu.com/question/60042037/answer/3601970421)

---

## 🚀 Phase 2: 实验室研究方向入门路线

> 请根据你加入实验室时选定的主要研究方向 (Track)，选择以下其中一条路径进行深入学习。

### 🏠 Direction A: Recommender Systems (推荐系统)

> **Goal:** 深入理解推荐系统范式，掌握经典模型，并进入实验室核心研究领域。

#### 1. 工业界推荐范式 (The Paradigm Shift)

* **A. 经典漏斗范式 (Funnel)**:
    * *定义*: 平衡精度与时延的标准架构。**召回 (Recall)** $\rightarrow$ **粗排** $\rightarrow$ **精排 (Ranking)** $\rightarrow$ **重排**。
    * 📚 **Reference**: [小红书工业级推荐系统公开课](https://www.bilibili.com/video/BV1HZ421U77y/?spm_id_from=333.337.search-card.all.click&vd_source=d7479f6f80547bcca48d3e2d18bd7178) | [知乎-互联网大厂推荐算法实战](https://zhuanlan.zhihu.com/p/617615036)
* **B. 生成式范式 (Generative)**:
    * *定义*: 随着 LLM 兴起，将推荐视为**序列生成问题** (Next Item Prediction)，不再依赖多阶段漏斗。
    * 📚 **Reference**: [Generative Recommendation Survey](https://www.preprints.org/manuscript/202512.0203) | [Awesome Large Recommendation Models](https://github.com/USTC-StarTeam/Awesome-Large-Recommendation-Models)

##### 🟢 下限标准：Pass The Quiz (核心概念)

<details>
<summary><strong>1. 架构: 为什么工业界不直接用最复杂的精排模型对全库几亿个商品打分？</strong></summary>

> 答案: **时延 (Latency) 与算力成本**。精排模型通常特征复杂、计算量大，无法在几十毫秒内处理全库数据。召回层的作用就是快速（低成本）地将候选集从“亿级”筛选到“千级”，为精排争取计算时间。
</details>

<details>
<summary><strong>2. 区别: 传统推荐 (Discriminative) 和 生成式推荐 (Generative) 在“输出层面”有什么核心区别？</strong></summary>

> 答案: 
> *   **传统推荐**通常是**分类/回归问题**：输入 User+Item，输出点击概率 (CTR) 或评分 (Rating)。
> *   **生成式推荐**通常是**生成问题**：输入 User History，直接生成下一个 Item 的 ID (Token) 或描述文本。
</details>

<details>
<summary><strong>3. 召回: "双塔模型 (Two-Tower)" 是召回还是排序？为什么？</strong></summary>

> 答案: 通常用于**召回**。因为双塔将 User 和 Item 分别编码为向量，线上推断时只需计算点积 (Dot Product) 或利用 ANN (近似最近邻) 检索，速度极快，适合处理海量候选集。
</details>

##### 🔵 上限标准：Explore More (深度视野)

*   **The Hallucination Problem**: 生成式推荐的一个致命弱点是“生成不存在的 Item ID”。请搜索并了解 **"Collision-free Indexing"** 或 **"Hierarchical Indexing"** 是如何尝试解决这个问题的。
*   **Vector Database**: 动手玩一下 **[Milvus](https://milvus.io/)** 或 **[Faiss](https://github.com/facebookresearch/faiss)**。理解在亿级数据下，如何通过 HNSW 等算法在毫秒级内完成向量检索（这是召回层的基石）。

---

#### 2. 代表性技术与论文 (Roadmap)

**🚩 Step 1: 深度表示学习 (Deep Representation)**
*解决问题：如何从海量稀疏数据中学习 User/Item Embedding？*
* **图神经网络**: **`LightGCN`** (SIGIR 2020) | 📄 [Paper](https://arxiv.org/abs/2002.02126) | 💻 [Code (Official)](https://github.com/kuandeng/LightGCN)
* **序列建模**: **`SASRec`** (ICDM 2018) | 📄 [Paper](https://arxiv.org/abs/1808.09781) | 💻 [Code (Official)](https://github.com/kang205/SASRec)
* **跨域推荐**: **`C2DSR`** (WSDM 2022) | 📄 [Paper](https://dl.acm.org/doi/10.1145/3488560.3498394) | 💻 [Code (Official)](https://github.com/JarenceSJ/C2DSR)

##### 🟢 下限标准：Pass The Quiz (模型机理)

<details>
<summary><strong>1. LightGCN: 相比于标准的 GCN，LightGCN 删除了哪两个关键组件？为什么要删除？</strong></summary>

> 答案: 删除了 **特征变换矩阵 (Feature Transformation)** 和 **非线性激活函数 (Non-linear Activation)**。
> <br>原因: 作者认为这两个组件在分类任务中有用，但在协同过滤 (CF) 任务中，仅需聚合邻居信息即可，过多的非线性变换反而会增加训练难度并导致过拟合。
</details>

<details>
<summary><strong>2. SASRec vs RNN: 在训练效率上，SASRec (Transformer) 相比 GRU4Rec (RNN) 最大的优势是什么？</strong></summary>

> 答案: **并行化计算 (Parallelism)**。RNN 必须按时间步 $t_1, t_2...$ 依次计算，无法并行；而 Transformer 利用 Masked Self-Attention 可以一次性并行计算序列中所有位置的 Attention score。
</details>

<details>
<summary><strong>3. 位置编码: 既然 Self-Attention 是“无序”的集合运算，SASRec 是如何感知用户行为的先后顺序的？</strong></summary>

> 答案: 通过引入可学习的 **Positional Embedding $P$**。输入 = Item Embedding $E$ + Positional Embedding $P$。如果去掉 $P$，模型将无法区分“先买手机后买壳”和“先买壳后买手机”。
</details>

##### 🔵 上限标准：Explore More (代码与进阶)

*   **Oversmoothing (过平滑)**: 为什么 LightGCN 的层数通常只有 3-4 层？如果堆叠 100 层会发生什么？尝试阅读关于 *GNN Oversmoothing* 的资料，理解为什么层数太深会导致所有节点的 Embedding 趋同。
*   **Embedding Visualization**: 学会使用 **t-SNE** 或 **UMAP** 工具。尝试将训练好的 `SASRec` Item Embedding 降维可视化到二维平面，看看属于同一类别的物品（如科幻电影）是否聚在一起？
*   **Contrastive Learning (对比学习)**: 如果你已经吃透了 SASRec，请阅读 **[CL4SRec](https://arxiv.org/abs/2010.14395)**。思考一下：通过 Data Augmentation（如随机删除、打乱序列）来辅助训练，为什么能提升效果？

<br>

**🚩 Step 2: 用户兴趣建模 (User Interest Modeling)**
*解决问题：如何精准捕捉用户兴趣与上下文？*
* **特征交互**
    * **传统方法**: **`DCNv2`** (WWW 2021) | Deep网络和Cross网络实现高阶特征交互 | 📄 [Paper](https://arxiv.org/abs/2008.13535)
    * **前沿热点**: **`OneTrans`** (Arxiv) | 序列与非序列特征交互的探索 | 📄 [Paper](https://arxiv.org/abs/2510.26104)
* **长序列建模**
    * **`DIN`** (KDD 2018) | 引入 Attention 捕获用户兴趣多样性 (Deep Interest Network) | 📄 [Paper](https://arxiv.org/abs/1706.06978) | 💻 [Code (Official)](https://github.com/zhougr1993/DeepInterestNetwork)
    * **`SIM`** (CIKM 2020) | 引入 两阶段范式（GSU-ESU）实现工业约束下的用户兴趣建模 | 📄 [Paper](https://arxiv.org/pdf/2006.05639)
    * **`TWIN`** (KDD 2023) | 实现两阶段范式下目标一致的共同优化 | 📄 [Paper](https://dl.acm.org/doi/pdf/10.1145/3580305.3599922)

##### 🟢 下限标准：Pass The Quiz (机制理解)

<details>
<summary><strong>1. DIN vs Embedding&MLP: 在预测不同候选商品（Candidate Item）时，DIN 生成的用户 Embedding 是一样的吗？</strong></summary>

> 答案: **不一样（这是 DIN 的核心）**。
> <br>传统的 Embedding&MLP 将用户历史取平均，无论预测什么商品，用户表示都是固定的。
> <br>DIN 使用 **Target Attention**，根据当前的 Candidate Item（如“泳衣”）去用户历史中加权检索相关的行为（如“泳镜”权重高，“键盘”权重低），因此用户向量是动态变化的。
</details>

<details>
<summary><strong>2. 特征交互: 既然 MLP (多层感知机) 理论上能拟合任何函数，为什么还需要 DCN 或 FM 显式地做特征交叉？</strong></summary>

> 答案: **学习效率与归纳偏置 (Inductive Bias)**。MLP 实际上很难通过隐式的方式高效学到类似于 $x_1 \times x_2$ 这样的乘法特征交互（Multiplicative Interaction）。DCN/FM 强制模型显式计算交叉项，收敛更快，效果更稳。
</details>

<details>
<summary><strong>3. 长序列 (SIM): 为什么不能直接把用户过去 3 年的 10,000 条行为输入到 Attention 模型中？</strong></summary>

> 答案: **工程时延 (Latency)**。Attention 的计算复杂度通常与序列长度呈线性或平方关系。在线服务要求 < 30ms 返回结果，直接计算万级序列不可行。因此 SIM 提出了 **GSU (General Search Unit)**，先通过简单的规则（如类目匹配）快速筛选出 Top-K 相关行为，再输入精排模型。
</details>

##### 🔵 上限标准：Explore More (架构思考)

*   **Two-Stage Inconsistency (两阶段不一致性)**: 在 SIM 中，GSU（负责快速筛选）和 ESU（负责精准打分）通常是分开训练甚至是基于规则的。这会导致 GSU 筛选出来的行为可能并不是 ESU 最需要的。**TWIN** 是如何通过一致性正则化（Consistency Regularization）解决这个问题的？
*   **Target Attention vs Self-Attention**: 对比 **DIN** 和 **SASRec**。
    *   DIN 是 `Query=Candidate Item, Key/Value=User History`。
    *   SASRec 是 `Query=History, Key/Value=History`。
    *   思考：为什么 **CTR 预估**（Ranking 阶段）多用 DIN 类结构，而 **召回/Next-Item 预测** 多用 SASRec 类结构？
*   **OneTrans 的野心**: 阅读 OneTrans 论文，看它是如何尝试打破“特征交互（DCN）”和“序列建模（Transformer）”之间的界限的？是否所有的特征本质上都可以被视为一种 Sequence？

<br>

**🚩 Step 3: 大模型与生成式推荐 (LLM4Rec & RecLLM)**
*解决问题：如何利用 LLM 的通识能力与推理能力？如何实现推荐模型的 scaling？*
* **LLM4Rec**
    * **`P5`** (RecSys 2022) | “One Model for All”理念在推荐领域的早期代表 | 📄 [Paper](https://arxiv.org/abs/2203.13366) | 💻 [Code (Official)](https://github.com/jeykigung/P5)
    * **`LLaRA`** (SIGIR 2024) | 结合推荐 ID Embedding 和 LLM 语义 | 📄 [Paper](https://arxiv.org/abs/2312.02445v2) | 💻 [Code (Official)](https://github.com/ljy0ustc/LLaRA)
    * **`TALLRec`** (RecSys 2023) | 微调和对齐 LLM 的语义到推荐 | 📄 [Paper](https://arxiv.org/abs/2305.00447) | 💻 [Code (Official)](https://github.com/SAI990323/TALLRec)
* **RecLLM**
    * **`TIGER`** (NeurIPS 2023) | 最早提出 Tokenizer 思想的框架 | 📄 [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/20dcab0f14046a5c6b02b61da9f13229-Paper-Conference.pdf)
    * **`HSTU`** (ICML 2024) | Meta 的生成式推荐框架 | 📄 [Paper](https://arxiv.org/abs/2402.17152) | 💻 [Code (Meta Generative Recs)](https://github.com/meta-recsys/generative-recommenders)
    * **`OneRec`** (Arxiv) | 快手的生成方式推荐框架 | 📄 [Paper](https://arxiv.org/abs/2502.18965) | 💻 [Code (MiniOneRec)](https://github.com/AkaliKong/MiniOneRec)
    * **`OneRec-Think`** (Arxiv) | 推理推荐大模型框架 | 📄 [Paper](https://arxiv.org/abs/2510.11639) | 💻 [Code (Official)](https://github.com/wangshy31/OneRec-Think)

##### 🟢 下限标准：Pass The Quiz (范式革命)

<details>
<summary><strong>1. ID vs. Text (LLaRA): 既然 LLM 语义理解能力这么强，为什么我们不能直接把 Item Title 喂给 LLM 做推荐，而通过 LLaRA 这种方式引入 ID Embedding？</strong></summary>

> 答案: **协作信号缺失 (Lack of Collaborative Signal)**。
> <br>仅仅依靠文本（如“iPhone 15”和“手机壳”），LLM 只能推断出它们语义相似，但无法知道“买过 A 的人通常买 B”这种基于群体行为的协同过滤信息。ID Embedding 浓缩了这种协同信号，是纯文本无法替代的。
</details>

<details>
<summary><strong>2. 生成式困境 (TIGER/OneRec): 如果把推荐看作生成问题，LLM 直接生成 "Item ID" 会遇到什么问题？</strong></summary>

> 答案: **词表爆炸与无语义 (Vocab Explosion & Semantics)**。
> <br>传统的 Item ID (如 "item_4829") 对 LLM 来说没有语义。且 Item 数量通常是百万级，远超 LLM 的词表大小 (30k-100k)。TIGER 提出的解决方案是 **RQ-VAE**，将 Item ID 离散化为几个语义 Token 的组合 (Tuple)，从而适配 LLM 的生成过程。
</details>

<details>
<summary><strong>3. 推理 (OneRec-Think): 什么是 Chain-of-Thought (CoT) 在推荐中的应用？它解决了传统推荐的什么痛点？</strong></summary>

> 答案: 传统推荐是“黑盒”，只输出结果。CoT 允许模型在输出推荐结果前，先生成一段**推理过程**（如“因为用户喜欢科幻，且最近看了流浪地球...”）。这不仅提升了**可解释性**，在某些复杂场景（如制定旅游计划、复杂的跨域推荐）下还能通过“慢思考”提升准确率。
</details>

##### 🔵 上限标准：Explore More (未来定义者)

*   **Scaling Law (尺度定律)**: 阅读 **HSTU** 论文。Meta 发现随着算力增加，基于 Attention 的模型在推荐任务上的性能提升远超传统模型。请思考：推荐系统的 Scaling Law 和 NLP 的 Scaling Law 有什么区别？（提示：数据质量/信噪比的差异）。
*   **World Model for RecSys**: 既然 LLM 可以模拟人类对话，它能否模拟**用户行为环境**？尝试阅读关于 **Generative Agents** 或 **RecSim** 的论文，思考如何用 LLM 构建一个虚拟的用户群体来评测推荐系统，而不是依赖离线数据集。
*   **In-Context Learning (ICL)**: 在不微调模型参数的情况下，如何通过设计精妙的 Prompt（包含用户最近的 10 个交互历史），激发通用大模型（如 DeepSeek/GPT-4）的推荐能力？尝试在一个小数据集上对比 ICL 和 Fine-tuning 的效果差异。

---

#### 3. StarTeam 创新研究: Data-Centric RecSys

核心理念：Better Data 和 Better Model 同等重要。

* **1. Data Regeneration (数据重生成)**
    * *原理*: 针对序列推荐中的噪声与稀疏问题，利用生成模型重构（Regenerate）更加纯净、鲁棒的用户交互序列。
    * 📄 **Paper**: [KDD 2024, Best Student Paper](https://dl.acm.org/doi/10.1145/3637528.3671841)
    * 💻 **Code**: [USTC-StarTeam/DR4SR](https://github.com/USTC-StarTeam/DR4SR)

* **2. Data Distillation (数据蒸馏)**
    * *原理*: 从海量历史交互中学习得到最具信息量的“核心摘要”，在大幅降低训练开销的同时保持模型性能。
    * 📄 **Paper**: [WWW 2025](https://dl.acm.org/doi/10.1145/3696410.3714613)
    * 💻 **Code**: [USTC-StarTeam/TD3](https://github.com/USTC-StarTeam/TD3)

* **3. Data Self-Evolution (数据自进化)**
    * *原理*: 探索数据在训练过程中的自我迭代与优化机制，利用 Agent 或进化策略让数据质量随模型能力螺旋上升。
    * 📄 **Paper**: [OpenReview](https://openreview.net/pdf?id=Q8HRE2E5wp)

* **4. Performance Law (引入数据质量因素的模型性能尺度定律)**
    * *原理*: 解决通用尺度定律仅考虑数据规模、未考虑数据质量，且忽视了模型损失和性能之间非线性关系的缺陷。
    * 📄 **Paper**: [NeurIPS 2025](https://neurips.cc/virtual/2025/loc/san-diego/poster/119100)
    * 💻 **Code**: [USTC-StarTeam/P-Law](https://github.com/USTC-StarTeam/P-Law)

##### 🟢 下限标准：Pass The Quiz (组内通识)

<details>
<summary><strong>1. 观念挑战 (Regeneration): 既然用户的行为是客观发生的（Ground Truth），为什么我们认为它需要被“重生成”或修改？</strong></summary>

> 答案: **噪声 (Noise) 与 意图偏差 (Gap)**。
> <br>用户点击不代表真的喜欢（可能是误触或诱导点击）；用户没点击也不代表不喜欢（可能是没看到）。原始数据充斥着噪声，直接以此训练模型会拟合噪声。重生成的目的是还原用户**潜在的真实意图序列**。
</details>

<details>
<summary><strong>2. 核心区别 (Distillation): 数据蒸馏 (Distillation) 和 随机采样 (Random Sampling) 都能减少数据量，核心区别是什么？</strong></summary>

> 答案: **信息密度 (Information Density)**。
> <br>随机采样会均匀地丢失信息，导致模型性能大幅下降。数据蒸馏是通过优化算法（如梯度匹配），合成出少量但**“浓缩”**了原始数据集核心梯度信息的样本，力求在极小的数据集上达到接近全量的效果。
</details>

<details>
<summary><strong>3. 盲点 (Performance Law): 传统的 Scaling Law (如 Chinchilla) 告诉我们数据越多越好，它忽略了什么关键维度？</strong></summary>

> 答案: **数据质量 (Quality)**。
> <br>如果你喂给模型 1TB 的垃圾数据，性能反而会下降。P-Law 首次将数据质量量化，并揭示了 **Training Loss**（训练损失）和 **Ranking Metrics**（如 NDCG）之间是非线性的——Loss 降低 10% 不代表 NDCG 也能涨 10%。
</details>

##### 🔵 上限标准：Explore More (思维共振)

*   **Andrew Ng's Vision**: 观看 Andrew Ng 发起的 **[Data-Centric AI Competition](https://https-deeplearning-ai.github.io/data-centric-1/)**。思考：在推荐系统中，除了清洗数据，我们还能通过什么手段（Prompt Engineering? CoT?）来提升数据质量？
*   **Model Collapse (模型崩溃)**: 这是一个反直觉的现象——如果模型完全由 AI 生成的数据训练，几代之后会发生“崩溃”。阅读关于 **[The Curse of Recursion](https://arxiv.org/abs/2305.17493)** 的文章。思考本组的 **Data Self-Evolution** 是如何通过引入外部反馈或多样性机制来避免这种崩溃的？
*   **Physics of AI**: P-Law 的本质是在寻找深度学习的物理规律。尝试阅读 **[The Science of Deep Learning](https://arxiv.org/abs/2307.04721)** 这类综述，思考如何用更严谨的数学工具（如信息瓶颈理论 IB）来解释为什么 Data Distillation 是有效的？

---

#### 4. 代码库与实战 (Hands-on)
*Talk is cheap, show me the code.* 建议根据你的研究阶段，按顺序探索以下代码库。

*   **🟢 Level 1: 学术入门与全能框架 - [RecBole](https://recbole.io/)**
    *   *Task*: 下载 `ML-1M` 数据集，运行 `LightGCN` 和 `SASRec` 模型，记录并对比两者的 Hit Ratio@10 和 NDCG@10。
*   **🟡 Level 2: 工业界精排与 CTR 预估 - [FuxiCTR](https://github.com/xue-pai/FuxiCTR)**
    *   *Task*: 尝试修改 FuxiCTR 的 YAML 配置文件，在 `Criteo` 采样数据集上跑通 `FinalMLP` 或 `DCNv2`。
*   **🔴 Level 3: 生成式推荐与大模型 - [Generative Recommenders](https://github.com/meta-recsys/generative-recommenders)**
    *   *Task*: 阅读 `HSTU` 的 Attention 实现细节，理解它为何比传统的 Transformer (SASRec) 快 5-10 倍。

---

### 🤖 Direction B: Large Language Models (大模型)

> **Goal:** 掌握 LLM 的训练、微调与对齐技术，探索 Agent 与多模态的前沿应用。

🚧 **Under Construction** 🚧

*   *Coming soon...*

<br>

### 🧬 Direction C: AI4Science (科学智能)

> **Goal:** 利用 AI 解决物理、化学、生物等领域的科学难题 (AI for Science)。

🚧 **Under Construction** 🚧

*   *Coming soon...*

---

## 🤝 Contributing

这份文档是活的 (Living Document)。如果你发现了新的好资源，或者踩过了一个文档里没写的坑：

1.  Fork 本仓库。
2.  修改 `README.md`。
3.  提交 Pull Request (PR)。

**Let's build a better lab wiki together!** 🚀

---
<div align="center">
  <sub>Maintained by StarTeam Students</sub>
</div>
